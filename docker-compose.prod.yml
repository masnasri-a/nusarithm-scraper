version: '3.8'

services:
  # Main API application (Production)
  scraper-api:
    build: 
      context: .
      dockerfile: Dockerfile  # Use production dockerfile
    ports:
      - "6777:6777"
    env_file:
      - .env
    volumes:
      - scraper_data:/app/data
      - scraper_logs:/app/logs
    restart: unless-stopped
    depends_on:
      - redis
      - postgres
    networks:
      - scraper-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6777/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

  # Frontend application (Production)
  scraper-frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.simple
    env_file:
      - .env
    environment:
      - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL:-http://localhost:6777}
      - NODE_ENV=production
      - PORT=3677
    restart: unless-stopped
    depends_on:
      - scraper-api
    networks:
      - scraper-network

  # Nginx reverse proxy
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./docker/nginx.prod.conf:/etc/nginx/nginx.conf:ro
      - ./docker/ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      - scraper-api
      - scraper-frontend
    restart: unless-stopped
    networks:
      - scraper-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  scraper_data:
    driver: local
  scraper_logs:
    driver: local
  nginx_logs:
    driver: local

networks:
  scraper-network:
    driver: bridge